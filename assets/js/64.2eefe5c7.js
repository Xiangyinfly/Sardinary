(window.webpackJsonp=window.webpackJsonp||[]).push([[64],{583:function(t,s,a){"use strict";a.r(s);var n=a(2),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("p",[t._v("主要分析了 Redis Scan 命令基本使用和具体实现，包括 Count 参数与 Scan 总耗时的关系，以及核心的逆二进制迭代算法分析。")]),t._v(" "),s("h2",{attrs:{id:"_1-概述"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-概述"}},[t._v("#")]),t._v(" "),s("strong",[t._v("1. 概述")])]),t._v(" "),s("p",[t._v("由于 Redis 是单线程在处理用户的命令，而 Keys 命令会一次性遍历所有 Key，于是在 命令执行过程中，无法执行其他命令。这就导致如果 Redis 中的 key 比较多，那么 Keys 命令执行时间就会比较长，从而阻塞 Redis。")]),t._v(" "),s("p",[t._v("所以很多教程都推荐使用 Scan 命令来代替 Keys，因为 Scan 可以限制每次遍历的 key 数量。")]),t._v(" "),s("p",[t._v("Keys 的缺点：")]),t._v(" "),s("ul",[s("li",[t._v("1）没有limit，我们只能一次性获取所有符合条件的key，如果结果有上百万条，那么等待你的就是“无穷无尽”的字符串输出。")]),t._v(" "),s("li",[t._v("2）keys命令是遍历算法，时间复杂度是O(N)。如我们刚才所说，这个命令非常容易导致Redis服务卡顿。因此，我们要尽量避免在生产环境使用该命令。")])]),t._v(" "),s("p",[t._v("相比于keys命令，Scan命令有两个比较明显的优势：")]),t._v(" "),s("ul",[s("li",[t._v("1）Scan命令的时间复杂度虽然也是O(N)，但它是分次进行的，不会阻塞线程。")]),t._v(" "),s("li",[t._v("2）Scan命令提供了 count 参数，可以控制每次遍历的集合数。")])]),t._v(" "),s("blockquote",[s("p",[t._v("可以理解为 Scan 是渐进式的 Keys。")])]),t._v(" "),s("p",[t._v("Scan 命令语法如下：")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("SCAN cursor[MATCH pattern][COUNT count]\n\n")])])]),s("hr"),t._v(" "),s("ul",[s("li",[t._v("cursor - 游标。")]),t._v(" "),s("li",[t._v("pattern - 匹配的模式。")]),t._v(" "),s("li",[t._v("count - 指定每次遍历多少个集合。\n"),s("ul",[s("li",[t._v("可以简单理解为每次遍历多少个元素")]),t._v(" "),s("li",[t._v("根据测试，推荐 Count大小为 1W。")])])])]),t._v(" "),s("p",[t._v("Scan 返回值为数组，会返回一个游标+一系列的 Key")]),t._v(" "),s("p",[t._v("大致用法如下：")]),t._v(" "),s("p",[t._v("SCAN命令是基于游标的，每次调用后，都会返回一个游标，用于下一次迭代。当游标返回0时，表示迭代结束。")]),t._v(" "),s("blockquote",[s("p",[t._v("第一次 Scan 时指定游标为 0，表示开启新的一轮迭代，然后 Scan 命令返回一个新的游标，作为第二次 Scan 时的游标值继续迭代，一直到 Scan 返回游标为0，表示本轮迭代结束。")])]),t._v(" "),s("p",[t._v("通过这个就可以看出，"),s("strong",[t._v("Scan 完成一次迭代，需要和 Redis 进行多次交互")]),t._v("。")]),t._v(" "),s("p",[t._v("Scan 命令注意事项：")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("返回的结果可能会有重复，需要客户端去重复，这点非常重要;")])]),t._v(" "),s("li",[s("strong",[t._v("遍历的过程中如果有数据修改，改动后的数据能不能遍历到是不确定的;")])]),t._v(" "),s("li",[s("strong",[t._v("单次返回的结果是空的并不意味着遍历结束，而要看返回的游标值是否为零;")])])]),t._v(" "),s("h2",{attrs:{id:"_2-scan-踩坑"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-scan-踩坑"}},[t._v("#")]),t._v(" "),s("strong",[t._v("2. Scan 踩坑")])]),t._v(" "),s("p",[t._v("使用时遇到一个 特殊场景，"),s("strong",[t._v("跨区域远程连接 Redis 并进行模糊查询")]),t._v("，扫描所有指定前缀的 Key。")]),t._v(" "),s("p",[t._v("最开始也没多想，直接就是开始 Scan，然后 Count 参数指定的是 1000。")]),t._v(" "),s("blockquote",[s("p",[t._v("Redis 中大概几百万 Key。")])]),t._v(" "),s("p",[t._v("最后发现这个接口需要几十上百秒才返回。")]),t._v(" "),s("p",[t._v("什么原因呢？")]),t._v(" "),s("p",[t._v("Scan 命令中的 Count 指定一次扫描多少 Key，这里指定为 1000，几百万Key就需要几千次迭代，即和 Redis 交互几千次，然后因为是远程连接，网络延迟比较大，所以耗时特别长。")]),t._v(" "),s("p",[t._v("最后将 Count 参数调大后，减少了交互次数，就好多了。")]),t._v(" "),s("blockquote",[s("p",[t._v("Count 参数越大，Redis 阻塞时间也会越长，需要取舍。")]),t._v(" "),s("p",[t._v("极限一点，"),s("strong",[t._v("Count 参数和总 Key 数一致时，Scan 命令就和 Keys 效果一样了")]),t._v("。")])]),t._v(" "),s("p",[t._v("Count 大小和 Scan 总耗时的关系如下图：")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://github.com/lixd/blog/raw/master/images/redis/scan/scan_time_vs_count.png",alt:"https://github.com/lixd/blog/raw/master/images/redis/scan/scan_time_vs_count.png"}})]),t._v(" "),s("blockquote",[s("p",[t._v("图源：keydb")])]),t._v(" "),s("p",[t._v("可以发现 Count 越大，总耗时就越短，不过越后面提升就越不明显了。")]),t._v(" "),s("blockquote",[s("p",[t._v("所以推荐的 Count 大小为 1W 左右。")])]),t._v(" "),s("p",[t._v("如果不考虑 Redis 的阻塞，其实 Keys 比 Scan 会快很多，毕竟一次性处理，省去了多余的交互。")]),t._v(" "),s("h2",{attrs:{id:"_3-scan原理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-scan原理"}},[t._v("#")]),t._v(" "),s("strong",[t._v("3. Scan原理")])]),t._v(" "),s("p",[t._v("Redis使用了Hash表作为底层实现，原因不外乎高效且实现简单。类似于HashMap那样数组+链表的结构。其中第一维的数组大小为2n(n>=0)。每次扩容数组长度扩大一倍。")]),t._v(" "),s("p",[t._v("Scan命令就是对这个一维数组进行遍历。每次返回的游标值也都是这个数组的索引。Count 参数表示遍历多少个数组的元素，将这些元素下挂接的符合条件的结果都返回。因为每个元素下挂接的链表大小不同，所以每次返回的结果数量也就不同。")]),t._v(" "),s("h3",{attrs:{id:"演示"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#演示"}},[t._v("#")]),t._v(" "),s("strong",[t._v("演示")])]),t._v(" "),s("p",[t._v("关于 Scan 命令的遍历顺序，我们可以用一个小栗子来具体看一下：")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v('127.0.0.1:6379> keys *\n1)"db_number"\n2)"key1"\n3)"myKey"\n127.0.0.1:6379> scan0 MATCH * COUNT1\n1)"2"\n2) 1)"db_number"\n127.0.0.1:6379> scan2 MATCH * COUNT1\n1)"1"\n2) 1)"myKey"\n127.0.0.1:6379> scan1 MATCH * COUNT1\n1)"3"\n2) 1)"key1"\n127.0.0.1:6379> scan3 MATCH * COUNT1\n1)"0"\n2)(empty list orset)\n\n')])])]),s("hr"),t._v(" "),s("p",[t._v("如上所示，SCAN命令的遍历顺序是：0->2->1->3")]),t._v(" "),s("p",[t._v("这个顺序看起来有些奇怪，我们把它转换成二进制：00->10->01->11")]),t._v(" "),s("p",[t._v("可以看到每次这个序列是高位加1的。")]),t._v(" "),s("blockquote",[s("p",[t._v("普通二进制的加法，是从右往左相加、进位。而这个序列是从左往右相加、进位的。")])]),t._v(" "),s("p",[t._v("相关源码：")]),t._v(" "),s("div",{staticClass:"language-c extra-class"},[s("pre",{pre:!0,attrs:{class:"language-c"}},[s("code",[t._v("v"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("rev")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nv"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nv"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("rev")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n")])])]),s("hr"),t._v(" "),s("p",[t._v("将游标倒置，加一后，再倒置，也就是我们所说的“高位加1”的操作。")]),t._v(" "),s("h3",{attrs:{id:"相关源码"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#相关源码"}},[t._v("#")]),t._v(" "),s("strong",[t._v("相关源码")])]),t._v(" "),s("p",[t._v("先贴一下代码：")]),t._v(" "),s("div",{staticClass:"language-c extra-class"},[s("pre",{pre:!0,attrs:{class:"language-c"}},[s("code",[t._v("\n")])])]),s("hr"),t._v(" "),s("h3",{attrs:{id:"reverse-binary-iteration"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#reverse-binary-iteration"}},[t._v("#")]),t._v(" "),s("strong",[t._v("reverse binary iteration")])]),t._v(" "),s("p",[t._v("Redis Scan 命令最终使用的是 reverse binary iteration 算法，大概可以翻译为 逆二进制迭代，具体算法细节可以看一下这个"),s("a",{attrs:{href:"https://github.com/redis/redis/pull/579",target:"_blank",rel:"noopener noreferrer"}},[t._v("Github 相关讨论"),s("OutboundLink")],1)]),t._v(" "),s("p",[t._v("这个算法简单来说就是：")]),t._v(" "),s("p",[s("strong",[t._v("依次从高位（有效位）开始，不断尝试将当前高位设置为1，然后变动更高位为不同组合，以此来扫描整个字典数组。")])]),t._v(" "),s("p",[t._v("其最大的优势在于，从高位扫描的时候，如果槽位是2^N个,扫描的临近的2个元素都是与2^(N-1)相关的就是说同模的，比如槽位8时，0%4 == 4%4， 1%4 == 5%4 ， 因此想到其实hash的时候，跟模是很相关的。")]),t._v(" "),s("p",[t._v("比如当整个字典大小只有4的时候，一个元素计算出的整数为5， 那么计算他的hash值需要模4，也就是hash(n) == 5%4 == 1 , 元素存放在第1个槽位中。当字典扩容的时候，字典大小变为8， 此时计算hash的时候为5%8 == 5 ， 该元素从1号slot迁移到了5号，1和5是对应的，我们称之为同模或者对应。")]),t._v(" "),s("p",[s("strong",[t._v("同模的槽位的元素最容易出现合并或者拆分了。因此在迭代的时候只要及时的扫描这些相关的槽位，这样就不会造成大面积的重复扫描。")])]),t._v(" "),s("h3",{attrs:{id:"_3-种情况"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-种情况"}},[t._v("#")]),t._v(" "),s("strong",[t._v("3 种情况")])]),t._v(" "),s("p",[t._v("迭代哈希表时，有以下三种情况：")]),t._v(" "),s("ul",[s("li",[t._v("从迭代开始到结束，哈希表不 Rehash；")]),t._v(" "),s("li",[t._v("从迭代开始到结束，哈希表Rehash，但每次迭代，哈希表要么不开始 Rehash，要么已经结束 Rehash；")]),t._v(" "),s("li",[t._v("从一次迭代开始到结束，哈希表在一次或多次迭代中 Rehash。\n"),s("ul",[s("li",[t._v("即再 Rehash 过程中，执行 Scan 命令，这时数据可能只迁移了一部分。")])])])]),t._v(" "),s("p",[t._v("因此，游标的实现需要兼顾以上三种情况。上述三种情况下游标实现的要求如下：")]),t._v(" "),s("p",[s("strong",[t._v("第一种情况比较简单")]),t._v("。假设redis的hash表大小为4，第一个游标为0，读取第一个bucket的数据，然后游标返回2，下次读取bucket 2 ，依次遍历。")]),t._v(" "),s("p",[s("strong",[t._v("第二种情况更复杂")]),t._v("。假设redis的hash表大小为4，如果rehash后大小变成8。如果如上返回游标(即返回2)，则显示下图：")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://github.com/lixd/blog/raw/master/images/redis/scan/redis-scale.png",alt:"https://github.com/lixd/blog/raw/master/images/redis/scan/redis-scale.png"}})]),t._v(" "),s("p",[t._v("假设bucket 0读取后返回到cursor 2，当客户端再次Scan cursor 2时，hash表已经被rehash，大小翻倍到8，redis计算一个key bucket如下：")]),t._v(" "),s("div",{staticClass:"language-c extra-class"},[s("pre",{pre:!0,attrs:{class:"language-c"}},[s("code",[s("span",{pre:!0,attrs:{class:"token function"}},[t._v("hash")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("hr"),t._v(" "),s("p",[t._v("即如果大小为4，hash(key)&11，如果大小为8，hash(key)&111。所以当size从4扩大到8时，2 号bucket中的原始数据会被分散到2 (010) 和 6 (110) 这两个 bucket中。")]),t._v(" "),s("blockquote",[s("p",[t._v("从二进制来看，size为4时，在hash(key)之后，取低两位，即hash(key)&11，如果size为8，bucket位置为hash(key) & 111，即取低三个位。")])]),t._v(" "),s("p",[t._v("所以依旧不会出现漏掉数据的情况。")]),t._v(" "),s("p",[s("strong",[t._v("第三种情况")]),t._v("，如果返回游标2时正在进行rehash，则Hash表1的bucket 2中的一些数据可能已经rehash到了的Hash表2 的bucket[2]或bucket[6]，那么必须完全遍历 哈希表2的 bucket 2 和 6，否则可能会丢失数据。")]),t._v(" "),s("blockquote",[s("p",[t._v("Redis 全局有两个Hash表，扩容时会渐进式的将表1的数据迁移到表2，查询时程序会先在 ht[0] 里面进行查找， 如果没找到的话， 就会继续到 ht[1] 里面进行查找。")]),t._v(" "),s("p",[t._v("详细信息可以查看："),s("a",{attrs:{href:"https://www.lixueduan.com/post/redis/04-global-datastructure/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Redis教程(四)—全局数据结构"),s("OutboundLink")],1)])]),t._v(" "),s("h3",{attrs:{id:"游标计算"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#游标计算"}},[t._v("#")]),t._v(" "),s("strong",[t._v("游标计算")])]),t._v(" "),s("p",[t._v("具体游标计算代码如下：")]),t._v(" "),s("blockquote",[s("p",[t._v("Scan 命令中的游标，其实就是 Redis 内部的 bucket。")])]),t._v(" "),s("div",{staticClass:"language-c extra-class"},[s("pre",{pre:!0,attrs:{class:"language-c"}},[s("code",[t._v("v"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|=")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("~")]),t._v("m0"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 将游标v的unmarsked 比特都置为1")]),t._v("\nv"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("rev")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 反转v")]),t._v("\nv"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//这个是关键，加1，对一个数加1，其实就是将这个数的低位的连续1变为0，然后将最低的一个0变为1，其实就是将最低的一个0变为1")]),t._v("\nv"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("rev")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//再次反转，即得到下一个游标值")]),t._v("\n\n")])])]),s("hr"),t._v(" "),s("p",[t._v("代码逻辑非常简单，计算过程如下：")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://github.com/lixd/blog/raw/master/images/redis/scan/scan-rbi.png",alt:"https://github.com/lixd/blog/raw/master/images/redis/scan/scan-rbi.png"}})]),t._v(" "),s("blockquote",[s("p",[t._v("图源：developpaper")])]),t._v(" "),s("ul",[s("li",[t._v("大小为 4 时，游标状态转换为 0-2-1-3。")]),t._v(" "),s("li",[t._v("当大小为 8 时，游标状态转换为 0-4-2-6-1-5-3-7。")])]),t._v(" "),s("p",[t._v("可以看出，当size由小变大时，所有原来的游标都能在大hashTable中找到对应的位置，并且顺序一致，不会重复读取，也不会被遗漏。")]),t._v(" "),s("p",[s("strong",[t._v("总结一下：redis在rehash 扩容的时候，不会重复或者漏掉数据。但缩容，可能会造成重复但不会漏掉数据。")])]),t._v(" "),s("h3",{attrs:{id:"缩容处理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#缩容处理"}},[t._v("#")]),t._v(" "),s("strong",[t._v("缩容处理")])]),t._v(" "),s("p",[s("strong",[t._v("之所以会出现重复数据，其实就是为了保证缩容后数据不丢。")])]),t._v(" "),s("p",[t._v("假设当前 hash 大小为 8：")]),t._v(" "),s("ul",[s("li",[t._v("1）第一次先遍历了 0 号槽，返回游标为 4；")]),t._v(" "),s("li",[t._v("2）准备遍历 4 号槽，然后此时发生了缩容，4 号槽的元素也进到 0 号槽了。")]),t._v(" "),s("li",[t._v("3）但是0 号槽之前已经被遍历过了，此时会丢数据吗？")])]),t._v(" "),s("p",[t._v("答案就在源码中：")]),t._v(" "),s("div",{staticClass:"language-c extra-class"},[s("pre",{pre:!0,attrs:{class:"language-c"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//扫描大点的表里面的槽位，注意这里是个循环，会将小表没有覆盖的slot全部扫描一次的")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/* Emit entries at cursor */")]),t._v("\nde"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("t1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v("table"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("m1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("de"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("fn")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("privdata"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("de"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nde"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("de"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v("next"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/* Increment bits not covered by the smaller mask */")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//下面的意思是，还需要扩展小点的表，将其后缀固定，然后看高位可以怎么扩充。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//其实就是想扫描一下小表里面的元素可能会扩充到哪些地方，需要将那些地方处理一遍。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//后面的(v & m0)是保留v在小表里面的后缀。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//((v | m0) + 1) & ~m0) 是想给v的扩展部分的二进制位不断的加1，来造成高位不断增加的效果。")]),t._v("\nv"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("m0"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("~")]),t._v("m0"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("m0"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/* Continue while bits covered by mask difference is non-zero */")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("m0"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("^")]),t._v("m1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//终止条件是 v的高位区别位没有1了，其实就是说到头了。")]),t._v("\n\n")])])]),s("hr"),t._v(" "),s("p",[t._v("具体计算方法：")]),t._v(" "),s("div",{staticClass:"language-c extra-class"},[s("pre",{pre:!0,attrs:{class:"language-c"}},[s("code",[t._v("v"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("m0"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("~")]),t._v("m0"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("m0"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n")])])]),s("hr"),t._v(" "),s("p",[t._v("右边的下半部分是v，左边的上半部分是v。 (v&m0) 取出v的低位，例如size=4时v&00000011")]),t._v(" "),s("p",[t._v("左半边(v|m0) + 1 将V 的低位设置为1，然后+1 将进位到v 的高位，再次&m0，V 的高位将被取出。")]),t._v(" "),s("p",[t._v("假设游标返回2并且正在rehashing，大小从4变为8，那么M0 = 00000011 v = 00000010")]),t._v(" "),s("p",[t._v("根据公式计算的下一个光标是 ((00000010 | 00000011) +1) & (11111111100) | (00000010 & 00000011) = (00000100) & (11111111100) | (00000000010) = (000000000110) 正好是 6。")]),t._v(" "),s("h2",{attrs:{id:"_4-小结"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-小结"}},[t._v("#")]),t._v(" "),s("strong",[t._v("4. 小结")])]),t._v(" "),s("ul",[s("li",[t._v("Scan Count 参数限制的是遍历的 bucket 数，而不是限制的返回的元素个数\n"),s("ul",[s("li",[t._v("由于不同 bucket 中的元素个数不同，其中满足条件的个数也不同，所以每次 Scan 返回元素也不一定相同")])])]),t._v(" "),s("li",[t._v("Count 越大，Scan 总耗时越短，但是单次耗时越大，即阻塞Redis 时间边长\n"),s("ul",[s("li",[t._v("推荐 Count 大小为 1W左右")]),t._v(" "),s("li",[t._v("当 Count = Redis Key 总数时，Scan 和 Keys 效果一致")])])]),t._v(" "),s("li",[t._v("Scan 采用 逆二进制迭代法来计算游标，主要为了兼容Rehash的情况")]),t._v(" "),s("li",[t._v("Scan 为了兼容缩容后不漏掉数据，会出现重复遍历。\n"),s("ul",[s("li",[t._v("即客户端需要做去重处理")])])])]),t._v(" "),s("p",[t._v("核心就是 逆二进制迭代法，比较复杂，而且算法作者也没有具体证明，为什么这样就能实现，只是测试发现没有问题，各种情况都能兼容。")]),t._v(" "),s("p",[t._v("具体算法细节可以看一下这个"),s("a",{attrs:{href:"https://github.com/redis/redis/pull/579",target:"_blank",rel:"noopener noreferrer"}},[t._v("Github 相关讨论"),s("OutboundLink")],1)]),t._v(" "),s("blockquote",[s("p",[t._v("antirez: Hello @pietern! I’m starting to re-evaluate the idea of an iterator for Redis, and the first item in this task is definitely to understand better your pull request and implementation. I don’t understand exactly the implementation with the reversed bits counter… I wonder if there is a way to make that more intuitive… so investing some more time into this, and if I fail I’ll just merge your code trying to augment it with more comments… Hard to explain but awesome.")]),t._v(" "),s("p",[s("strong",[t._v("pietern")]),t._v("： Although I don’t have a formal proof for these guarantees, I’m reasonably confident they hold. I worked through every hash table state (stable, grow, shrink) and it appears to work everywhere by means of the reverse binary iteration (for lack of a better word).")])]),t._v(" "),s("p",[t._v("所以只能说这个算法很巧妙。就像卡马克快速逆平方根算法：")]),t._v(" "),s("div",{staticClass:"language-c extra-class"},[s("pre",{pre:!0,attrs:{class:"language-c"}},[s("code",[s("span",{pre:!0,attrs:{class:"token function"}},[t._v("floatQ_rsqrt")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("floatnumber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\nlongi"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nfloatx2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nconstfloatthreehalfs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.5F")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nx2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("number"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5F")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\ny"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("number"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\ni"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("long")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// evil floating point bit level hacking")]),t._v("\ni"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0x5f3759df")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// what the fuck?")]),t._v("\ny"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("float")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\ny"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("threehalfs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 1st iteration")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//  y = y * ( threehalfs - ( x2 * y * y ) ); // 2nd iteration, this can be removed")]),t._v("\nreturny"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),s("hr"),t._v(" "),s("p",[t._v("其中的这个"),s("code",[t._v("0x5f3759df")]),t._v("数就很巧妙。")]),t._v(" "),s("h2",{attrs:{id:"_5-参考"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-参考"}},[t._v("#")]),t._v(" "),s("strong",[t._v("5. 参考")])]),t._v(" "),s("p",[s("code",[t._v("http://antirez.com/news/63")])]),t._v(" "),s("p",[s("code",[t._v("https://developpaper.com/redis-scan-command-principle/")])]),t._v(" "),s("p",[s("code",[t._v("https://www.cnblogs.com/thrillerz/p/4527510.html")])]),t._v(" "),s("p",[s("code",[t._v("https://www.jianshu.com/p/abe5d8ae4852")])]),t._v(" "),s("p",[s("code",[t._v("https://zhuanlan.zhihu.com/p/46353221")])]),t._v(" "),s("p",[s("code",[t._v("https://docs.keydb.dev/blog/2020/08/10/blog-post/")])])])}),[],!1,null,null,null);s.default=e.exports}}]);